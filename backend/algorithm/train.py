"""
è®­ç»ƒLSTMç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œè®¾å¤‡å‰©ä½™ä½¿ç”¨å¯¿å‘½ï¼ˆRULï¼‰é¢„æµ‹ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- ä»æ•°æ®åº“åŠ è½½è®­ç»ƒæ•°æ®
- å‡†å¤‡æ—¶é—´åºåˆ—è®­ç»ƒæ•°æ®ï¼ˆåºåˆ—åŒ–ã€å½’ä¸€åŒ–ç­‰ï¼‰
- æ„å»ºå’Œè®­ç»ƒLSTMæ¨¡å‹
- è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆMSEã€MAEã€RÂ²ç­‰ï¼‰
- ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œå¯è§†åŒ–å›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python -m backend.algorithm.train --asset_id COMP-ATLAS-01 --metric_id COMP01_OIL_TEMP

Author: EMSforAI Team
License: MIT
"""
import argparse
import logging
import sys
from pathlib import Path
from typing import Dict, Optional, List
import pandas as pd
from datetime import datetime
import numpy as np

BASE_DIR = Path(__file__).resolve().parents[2]
if str(BASE_DIR) not in sys.path:
    sys.path.append(str(BASE_DIR))

from backend.algorithm.data_service import load_data_from_db
from backend.algorithm.training_utils import (
    prepare_training_data,
    MAX_RUL_DAYS,
    print_section_header,
    print_info_box,
)
from backend.algorithm.lstm_model import LSTMRULPredictor, MultiVariateLSTMPredictor
from backend.algorithm.training_utils_multivariate import prepare_multivariate_training_data
from backend.algorithm.visualization import (
    plot_training_curves,
    plot_prediction_scatter,
    MATPLOTLIB_AVAILABLE,
)

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)


def train_single_metric(
    asset_id: str,
    metric_id: str,
    sequence_length: int = 30,
    lstm_units: list = [64, 32],
    epochs: int = 32,
    batch_size: int = 64,
    model_save_path: Optional[str] = None,
    save_plots: bool = True,
):
    """
    è®­ç»ƒå•ä¸ªæµ‹ç‚¹çš„LSTMæ¨¡å‹
    
    Args:
        asset_id: è®¾å¤‡ID
        metric_id: æµ‹ç‚¹ID
        sequence_length: åºåˆ—é•¿åº¦
        lstm_units: LSTMå±‚å•å…ƒæ•°
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        model_save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        save_plots: æ˜¯å¦ä¿å­˜è®­ç»ƒæ›²çº¿å›¾
    """
    start_time = datetime.now()
    
    print_section_header("ğŸš€ LSTMæ¨¡å‹è®­ç»ƒ", "â•", 70)
    print_info_box("ğŸ“‹ è®­ç»ƒé…ç½®", {
        "è®¾å¤‡ID": asset_id,
        "æµ‹ç‚¹ID": metric_id,
        "åºåˆ—é•¿åº¦": sequence_length,
        "LSTMå•å…ƒ": f"{lstm_units}",
        "è®­ç»ƒè½®æ•°": epochs,
        "æ‰¹æ¬¡å¤§å°": batch_size,
    })
    
    # åŠ è½½æ•°æ®
    print_section_header("ğŸ“Š æ­¥éª¤ 1/5: åŠ è½½æ•°æ®", "â”€", 70)
    try:
        data = load_data_from_db(asset_id=asset_id)
        print("âœ“ æ•°æ®åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print_section_header("ğŸ”§ æ­¥éª¤ 2/5: å‡†å¤‡è®­ç»ƒæ•°æ®", "â”€", 70)
    try:
        X_train, y_train, X_val, y_val, scaler = prepare_training_data(
            data, asset_id, metric_id, sequence_length=sequence_length
        )
        print("âœ“ è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
    except Exception as e:
        print(f"âœ— æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æ„å»ºæ¨¡å‹
    print_section_header("ğŸ—ï¸  æ­¥éª¤ 3/5: æ„å»ºLSTMæ¨¡å‹", "â”€", 70)
    predictor = LSTMRULPredictor(
        sequence_length=sequence_length,
        n_features=1,
        lstm_units=lstm_units,
    )
    predictor.scaler = scaler
    
    model = predictor.build_model()
    if model is None:
        print("âœ— æ¨¡å‹æ„å»ºå¤±è´¥")
        return
    
    total_params = sum(p.numel() for p in model.parameters())
    print_info_box("ğŸ“ æ¨¡å‹ç»“æ„", {
        "å‚æ•°æ•°é‡": f"{total_params:,}",
        "LSTMå±‚": f"{len(lstm_units)}å±‚",
        "LSTMå•å…ƒ": f"{lstm_units}",
        "Dropoutç‡": "0.2",
    })
    
    # è®­ç»ƒæ¨¡å‹
    print_section_header("ğŸ¯ æ­¥éª¤ 4/5: è®­ç»ƒæ¨¡å‹", "â”€", 70)
    
    try:
        history = predictor.train(
            X_train,
            y_train,
            X_val,
            y_val,
            epochs=epochs,
            batch_size=batch_size,
            verbose=1,
        )
        print("\nâœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # æ˜¾ç¤ºè®­ç»ƒå†å²æ‘˜è¦
        if history:
            final_train_loss = history.get("train_loss", [])[-1] if history.get("train_loss") else None
            final_val_loss = history.get("val_loss", [])[-1] if history.get("val_loss") else None
            best_epoch = np.argmin(history["val_loss"]) + 1 if history.get("val_loss") else len(history["train_loss"])
            
            print_info_box("ğŸ“ˆ è®­ç»ƒæ‘˜è¦", {
                "æœ€ä½³Epoch": best_epoch,
                "æœ€ç»ˆè®­ç»ƒæŸå¤±": f"{final_train_loss:.6f}" if final_train_loss else "N/A",
                "æœ€ç»ˆéªŒè¯æŸå¤±": f"{final_val_loss:.6f}" if final_val_loss else "N/A",
                "è®­ç»ƒè½®æ•°": len(history["train_loss"]),
            })
        
        # è¯„ä¼°æ¨¡å‹
        print_section_header("ğŸ“Š æ­¥éª¤ 5/5: è¯„ä¼°æ¨¡å‹", "â”€", 70)
        # é¢„æµ‹å¾—åˆ°çš„æ˜¯å½’ä¸€åŒ–åçš„RULï¼Œéœ€è¦è¿˜åŸåˆ°"å¤©"
        y_pred_train_scaled = predictor.predict(X_train)
        y_pred_val_scaled = predictor.predict(X_val)

        y_train_days = y_train * MAX_RUL_DAYS
        y_val_days = y_val * MAX_RUL_DAYS
        y_pred_train_days = y_pred_train_scaled * MAX_RUL_DAYS
        y_pred_val_days = y_pred_val_scaled * MAX_RUL_DAYS
        
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        train_mse = mean_squared_error(y_train_days, y_pred_train_days)
        train_mae = mean_absolute_error(y_train_days, y_pred_train_days)
        train_r2 = r2_score(y_train_days, y_pred_train_days)
        train_rmse = np.sqrt(train_mse)
        
        val_mse = mean_squared_error(y_val_days, y_pred_val_days)
        val_mae = mean_absolute_error(y_val_days, y_pred_val_days)
        val_r2 = r2_score(y_val_days, y_pred_val_days)
        val_rmse = np.sqrt(val_mse)
        
        metrics = {
            "train": {
                "mse": train_mse,
                "mae": train_mae,
                "r2": train_r2,
                "rmse": train_rmse,
            },
            "val": {
                "mse": val_mse,
                "mae": val_mae,
                "r2": val_r2,
                "rmse": val_rmse,
            }
        }
        
        print_info_box("ğŸ¯ è®­ç»ƒé›†æŒ‡æ ‡", {
            "MSE": f"{train_mse:.4f}",
            "RMSE": f"{train_rmse:.2f} å¤©",
            "MAE": f"{train_mae:.2f} å¤©",
            "R2": f"{train_r2:.4f}",
        })
        
        print_info_box("ğŸ¯ éªŒè¯é›†æŒ‡æ ‡", {
            "MSE": f"{val_mse:.4f}",
            "RMSE": f"{val_rmse:.2f} å¤©",
            "MAE": f"{val_mae:.2f} å¤©",
            "R2": f"{val_r2:.4f}",
        })
        
        # æ€§èƒ½è¯„ä»·
        print_section_header("ğŸ’¡ æ€§èƒ½è¯„ä»·", "â”€", 70)
        if val_r2 > 0.8:
            performance = "ä¼˜ç§€ â­â­â­â­â­"
            color_indicator = "ğŸŸ¢"
        elif val_r2 > 0.6:
            performance = "è‰¯å¥½ â­â­â­â­"
            color_indicator = "ğŸŸ¡"
        elif val_r2 > 0.4:
            performance = "ä¸€èˆ¬ â­â­â­"
            color_indicator = "ğŸŸ "
        elif val_r2 > 0:
            performance = "è¾ƒå·® â­â­"
            color_indicator = "ğŸ”´"
        else:
            performance = "å¾ˆå·® â­"
            color_indicator = "ğŸ”´"
        
        print(f"{color_indicator} æ¨¡å‹æ€§èƒ½: {performance}")
        print(f"   éªŒè¯é›†R2 = {val_r2:.4f}")
        print(f"   å¹³å‡è¯¯å·® = {val_mae:.2f} å¤©")
        print()
        
        # ä¿å­˜æ¨¡å‹å’Œå›¾è¡¨
        print_section_header("ğŸ’¾ ä¿å­˜ç»“æœ", "â”€", 70)
        
        # ä¿å­˜æ¨¡å‹
        if model_save_path:
            model_path = Path(model_save_path)
        else:
            models_dir = BASE_DIR / "models" / "lstm"
            models_dir.mkdir(parents=True, exist_ok=True)
            model_path = models_dir / f"{asset_id}_{metric_id}_lstm.pt"
        
        predictor.save_model(str(model_path))
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜è®­ç»ƒæ›²çº¿å›¾
        if save_plots and MATPLOTLIB_AVAILABLE:
            plots_dir = BASE_DIR / "models" / "lstm" / "plots"
            plots_dir.mkdir(parents=True, exist_ok=True)
            
            # è®­ç»ƒæ›²çº¿å›¾ï¼ˆåŒ…å«é¢„æµ‹æ•£ç‚¹å›¾ï¼‰
            plot_path = plots_dir / f"{asset_id}_{metric_id}_training_curves.png"
            plot_training_curves(
                history, metrics, plot_path, asset_id, metric_id,
                y_true_train=y_train_days, y_pred_train=y_pred_train_days,
                y_true_val=y_val_days, y_pred_val=y_pred_val_days
            )
            
            # é¢„æµ‹æ•£ç‚¹å›¾ï¼ˆè®­ç»ƒé›†ï¼‰
            scatter_train_path = plots_dir / f"{asset_id}_{metric_id}_scatter_train.png"
            plot_prediction_scatter(
                y_train_days, y_pred_train_days,
                scatter_train_path, asset_id, metric_id, "è®­ç»ƒé›†"
            )
            
            # é¢„æµ‹æ•£ç‚¹å›¾ï¼ˆéªŒè¯é›†ï¼‰
            scatter_val_path = plots_dir / f"{asset_id}_{metric_id}_scatter_val.png"
            plot_prediction_scatter(
                y_val_days, y_pred_val_days,
                scatter_val_path, asset_id, metric_id, "éªŒè¯é›†"
            )
        elif save_plots and not MATPLOTLIB_AVAILABLE:
            print("âš ï¸  matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡ç»˜å›¾")
        
        # è®­ç»ƒæ€»ç»“
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print_section_header("âœ… è®­ç»ƒå®Œæˆ", "â•", 70)
        print_info_box("â±ï¸  è®­ç»ƒä¿¡æ¯", {
            "å¼€å§‹æ—¶é—´": start_time.strftime("%Y-%m-%d %H:%M:%S"),
            "ç»“æŸæ—¶é—´": end_time.strftime("%Y-%m-%d %H:%M:%S"),
            "è®­ç»ƒæ—¶é•¿": f"{duration:.1f} ç§’",
            "æ¨¡å‹æ–‡ä»¶": str(model_path),
        })
        
        if save_plots and MATPLOTLIB_AVAILABLE:
            print(f"\nğŸ“Š è®­ç»ƒæ›²çº¿å›¾: {plots_dir / f'{asset_id}_{metric_id}_training_curves.png'}")
            print(f"ğŸ“Š é¢„æµ‹æ•£ç‚¹å›¾: {plots_dir / f'{asset_id}_{metric_id}_scatter_*.png'}")
        
        print()
        
    except Exception as e:
        print(f"\nâœ— è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def train_multivariate(
    asset_id: str,
    sequence_length: int = 30,
    lstm_units: list = [128, 64],
    epochs: int = 50,
    batch_size: int = 64,
    model_save_path: Optional[str] = None,
    save_plots: bool = True,
):
    """
    è®­ç»ƒå¤šå˜é‡LSTMæ¨¡å‹ï¼ˆä¸€ä¸ªè®¾å¤‡ä¸€ä¸ªæ¨¡å‹ï¼‰
    
    è‡ªåŠ¨ä»æ•°æ®åº“è·å–è®¾å¤‡çš„æ‰€æœ‰PROCESSç±»å‹æµ‹ç‚¹è¿›è¡Œè®­ç»ƒã€‚
    å¤šå˜é‡æ¨¡å‹å¯ä»¥åŒæ—¶å­¦ä¹ å¤šä¸ªæµ‹ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œé€šå¸¸æ¯”å•æµ‹ç‚¹æ¨¡å‹æœ‰æ›´å¥½çš„é¢„æµ‹æ€§èƒ½ã€‚
    
    è®­ç»ƒæµç¨‹ï¼š
    1. ä»æ•°æ®åº“åŠ è½½è®¾å¤‡æ•°æ®
    2. è‡ªåŠ¨è·å–è®¾å¤‡çš„æ‰€æœ‰PROCESSç±»å‹æµ‹ç‚¹ï¼ˆæœ‰ä¸´ç•Œé˜ˆå€¼çš„ï¼‰
    3. å‡†å¤‡å¤šå˜é‡è®­ç»ƒæ•°æ®ï¼ˆå¯¹é½æ—¶é—´æˆ³ã€æ ‡å‡†åŒ–ç­‰ï¼‰
    4. æ„å»ºå¤šå˜é‡LSTMæ¨¡å‹
    5. è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒæ—©åœï¼‰
    6. è¯„ä¼°æ¨¡å‹æ€§èƒ½
    7. ä¿å­˜æ¨¡å‹å’Œscaler
    
    Args:
        asset_id: è®¾å¤‡IDï¼Œä¾‹å¦‚"COMP-ATLAS-01"
        sequence_length: åºåˆ—é•¿åº¦ï¼Œå³æ—¶é—´çª—å£å¤§å°ï¼ˆé»˜è®¤30ï¼‰
        lstm_units: LSTMå±‚å•å…ƒæ•°åˆ—è¡¨ï¼Œä¾‹å¦‚[128, 64]è¡¨ç¤ºä¸¤å±‚LSTMï¼ˆé»˜è®¤[128, 64]ï¼‰
        epochs: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤50ï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤64ï¼‰
        model_save_path: æ¨¡å‹ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼ˆmodels/lstm/{asset_id}_multivariate_lstm.ptï¼‰
        save_plots: æ˜¯å¦ä¿å­˜è®­ç»ƒæ›²çº¿å›¾ï¼ˆé»˜è®¤Trueï¼‰
    
    Note:
        - æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰æµ‹ç‚¹çš„scalerï¼Œç¡®ä¿æ¨ç†æ—¶æ•°æ®é¢„å¤„ç†ä¸€è‡´
        - è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºè¯¦ç»†çš„è¿›åº¦ä¿¡æ¯å’Œæ€§èƒ½æŒ‡æ ‡
        - å¦‚æœéªŒè¯é›†RÂ² > 0.8ï¼Œæ¨¡å‹æ€§èƒ½è¯„ä»·ä¸º"ä¼˜ç§€"
    """
    start_time = datetime.now()
    
    # åŠ è½½æ•°æ®
    print_section_header("ğŸ“Š æ­¥éª¤ 1/6: åŠ è½½æ•°æ®", "â”€", 70)
    try:
        data = load_data_from_db(asset_id=asset_id)
        print("âœ“ æ•°æ®åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è‡ªåŠ¨è·å–è®¾å¤‡çš„æ‰€æœ‰PROCESSç±»å‹æµ‹ç‚¹
    print_section_header("ğŸ” æ­¥éª¤ 2/6: è·å–æµ‹ç‚¹åˆ—è¡¨", "â”€", 70)
    try:
        metric_defs = data.get("metric_definitions", pd.DataFrame())
        if metric_defs.empty:
            print("âœ— æœªæ‰¾åˆ°æµ‹ç‚¹å®šä¹‰æ•°æ®")
            return
        
        # è¿‡æ»¤å‡ºè¯¥è®¾å¤‡çš„PROCESSç±»å‹æµ‹ç‚¹
        asset_metrics = metric_defs[
            (metric_defs["asset_id"] == asset_id) &
            (metric_defs["metric_type"] == "PROCESS")
        ]
        
        if asset_metrics.empty:
            print(f"âœ— è®¾å¤‡ {asset_id} æ²¡æœ‰PROCESSç±»å‹çš„æµ‹ç‚¹")
            return
        
        # åªé€‰æ‹©æœ‰ä¸´ç•Œé˜ˆå€¼çš„æµ‹ç‚¹ï¼ˆç”¨äºRULè®¡ç®—ï¼‰
        asset_metrics = asset_metrics[asset_metrics["crit_threshold"].notna()]
        
        if asset_metrics.empty:
            print(f"âœ— è®¾å¤‡ {asset_id} æ²¡æœ‰é…ç½®ä¸´ç•Œé˜ˆå€¼çš„æµ‹ç‚¹")
            return
        
        # è·å–æµ‹ç‚¹IDåˆ—è¡¨
        metric_ids = asset_metrics["metric_id"].tolist()
        
        print(f"âœ“ æ‰¾åˆ° {len(metric_ids)} ä¸ªPROCESSç±»å‹æµ‹ç‚¹:")
        for i, metric_id in enumerate(metric_ids, 1):
            metric_name = asset_metrics[asset_metrics["metric_id"] == metric_id].iloc[0]["metric_name"]
            print(f"  {i}. {metric_id} ({metric_name})")
        
    except Exception as e:
        print(f"âœ— è·å–æµ‹ç‚¹åˆ—è¡¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print_section_header("ğŸš€ å¤šå˜é‡LSTMæ¨¡å‹è®­ç»ƒ", "â•", 70)
    print_info_box("ğŸ“‹ è®­ç»ƒé…ç½®", {
        "è®¾å¤‡ID": asset_id,
        "æµ‹ç‚¹æ•°é‡": len(metric_ids),
        "æµ‹ç‚¹åˆ—è¡¨": ", ".join(metric_ids[:5]) + (f" ... (å…±{len(metric_ids)}ä¸ª)" if len(metric_ids) > 5 else ""),
        "åºåˆ—é•¿åº¦": sequence_length,
        "LSTMå•å…ƒ": f"{lstm_units}",
        "è®­ç»ƒè½®æ•°": epochs,
        "æ‰¹æ¬¡å¤§å°": batch_size,
    })
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print_section_header("ğŸ”§ æ­¥éª¤ 3/6: å‡†å¤‡å¤šå˜é‡è®­ç»ƒæ•°æ®", "â”€", 70)
    try:
        X_train, y_train, X_val, y_val, scalers, feature_names = prepare_multivariate_training_data(
            data, asset_id, metric_ids, sequence_length=sequence_length
        )
        print("âœ“ å¤šå˜é‡è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
    except Exception as e:
        print(f"âœ— è®­ç»ƒæ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æ„å»ºæ¨¡å‹
    print_section_header("ğŸ—ï¸  æ­¥éª¤ 4/6: æ„å»ºæ¨¡å‹", "â”€", 70)
    try:
        predictor = MultiVariateLSTMPredictor(
            sequence_length=sequence_length,
            n_features=len(feature_names),
            lstm_units=lstm_units,
        )
        predictor.build_model()
        predictor.scalers = scalers  # ä¿å­˜æ‰€æœ‰æµ‹ç‚¹çš„scalerå­—å…¸
        predictor.feature_names = feature_names  # ä¿å­˜ç‰¹å¾åç§°åˆ—è¡¨
        print("âœ“ æ¨¡å‹æ„å»ºå®Œæˆ")
    except Exception as e:
        print(f"âœ— æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è®­ç»ƒæ¨¡å‹
    print_section_header("ğŸ“ æ­¥éª¤ 5/6: è®­ç»ƒæ¨¡å‹", "â”€", 70)
    try:
        history = predictor.train(
            X_train, y_train,
            X_val=X_val, y_val=y_val,
            epochs=epochs,
            batch_size=batch_size,
            verbose=1,
            patience=20,
        )
        print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
    except Exception as e:
        print(f"âœ— æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è¯„ä¼°æ¨¡å‹
    print_section_header("ğŸ“ˆ æ­¥éª¤ 6/6: è¯„ä¼°æ¨¡å‹", "â”€", 70)
    try:
        y_pred_train = predictor.predict(X_train)
        y_pred_val = predictor.predict(X_val)
        
        # åç¼©æ”¾RULï¼ˆä»[0,1]æ¢å¤åˆ°å¤©æ•°ï¼‰
        y_train_days = y_train * MAX_RUL_DAYS
        y_val_days = y_val * MAX_RUL_DAYS
        y_pred_train_days = y_pred_train * MAX_RUL_DAYS
        y_pred_val_days = y_pred_val * MAX_RUL_DAYS
        
        # è®¡ç®—æŒ‡æ ‡
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        train_mse = mean_squared_error(y_train_days, y_pred_train_days)
        train_rmse = np.sqrt(train_mse)
        train_mae = mean_absolute_error(y_train_days, y_pred_train_days)
        train_r2 = r2_score(y_train_days, y_pred_train_days)
        
        val_mse = mean_squared_error(y_val_days, y_pred_val_days)
        val_rmse = np.sqrt(val_mse)
        val_mae = mean_absolute_error(y_val_days, y_pred_val_days)
        val_r2 = r2_score(y_val_days, y_pred_val_days)
        
        metrics = {
            "train_mse": train_mse,
            "train_rmse": train_rmse,
            "train_mae": train_mae,
            "train_r2": train_r2,
            "val_mse": val_mse,
            "val_rmse": val_rmse,
            "val_mae": val_mae,
            "val_r2": val_r2,
        }
        
        print_info_box("ğŸ¯ è®­ç»ƒé›†æŒ‡æ ‡", {
            "MSE": f"{train_mse:.4f}",
            "RMSE": f"{train_rmse:.2f} å¤©",
            "MAE": f"{train_mae:.2f} å¤©",
            "R2": f"{train_r2:.4f}",
        })
        
        print_info_box("ğŸ¯ éªŒè¯é›†æŒ‡æ ‡", {
            "MSE": f"{val_mse:.4f}",
            "RMSE": f"{val_rmse:.2f} å¤©",
            "MAE": f"{val_mae:.2f} å¤©",
            "R2": f"{val_r2:.4f}",
        })
        
        # æ€§èƒ½è¯„ä»·
        print_section_header("ğŸ’¡ æ€§èƒ½è¯„ä»·", "â”€", 70)
        if val_r2 > 0.8:
            performance = "ä¼˜ç§€ â­â­â­â­â­"
            color_indicator = "ğŸŸ¢"
        elif val_r2 > 0.6:
            performance = "è‰¯å¥½ â­â­â­â­"
            color_indicator = "ğŸŸ¡"
        elif val_r2 > 0.4:
            performance = "ä¸€èˆ¬ â­â­â­"
            color_indicator = "ğŸŸ "
        elif val_r2 > 0:
            performance = "è¾ƒå·® â­â­"
            color_indicator = "ğŸ”´"
        else:
            performance = "å¾ˆå·® â­"
            color_indicator = "ğŸ”´"
        
        print(f"{color_indicator} æ¨¡å‹æ€§èƒ½: {performance}")
        print(f"   éªŒè¯é›†R2 = {val_r2:.4f}")
        print(f"   å¹³å‡è¯¯å·® = {val_mae:.2f} å¤©")
        print()
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ä¿å­˜æ¨¡å‹
    print_section_header("ğŸ’¾ ä¿å­˜ç»“æœ", "â”€", 70)
    
    if model_save_path:
        model_path = Path(model_save_path)
    else:
        models_dir = BASE_DIR / "models" / "lstm"
        models_dir.mkdir(parents=True, exist_ok=True)
        model_path = models_dir / f"{asset_id}_multivariate_lstm.pt"
    
    # ä¿å­˜æ¨¡å‹ï¼ˆåŒ…å«æ‰€æœ‰scalerï¼‰
    predictor.save_model(str(model_path))
    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # è®­ç»ƒæ€»ç»“
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print_section_header("âœ… è®­ç»ƒå®Œæˆ", "â•", 70)
    print_info_box("â±ï¸  è®­ç»ƒä¿¡æ¯", {
        "å¼€å§‹æ—¶é—´": start_time.strftime("%Y-%m-%d %H:%M:%S"),
        "ç»“æŸæ—¶é—´": end_time.strftime("%Y-%m-%d %H:%M:%S"),
        "è®­ç»ƒæ—¶é•¿": f"{duration:.1f} ç§’",
        "æ¨¡å‹æ–‡ä»¶": str(model_path),
        "æµ‹ç‚¹æ•°é‡": len(feature_names),
    })
    print()


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨è®­ç»ƒ
    
    æ”¯æŒä¸¤ç§è®­ç»ƒæ¨¡å¼ï¼š
    - single: å•æµ‹ç‚¹æ¨¡å¼ï¼Œè®­ç»ƒå•ä¸ªæµ‹ç‚¹çš„LSTMæ¨¡å‹
    - multivariate: å¤šå˜é‡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼Œè‡ªåŠ¨è·å–è®¾å¤‡çš„æ‰€æœ‰PROCESSç±»å‹æµ‹ç‚¹è¿›è¡Œè®­ç»ƒ
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # å¤šå˜é‡æ¨¡å¼ï¼ˆæ¨èï¼‰
        python -m backend.algorithm.train --mode multivariate --asset_id COMP-ATLAS-01
        
        # å•æµ‹ç‚¹æ¨¡å¼
        python -m backend.algorithm.train --mode single --asset_id COMP-ATLAS-01 --metric_id COMP01_OIL_TEMP
    """
    parser = argparse.ArgumentParser(
        description="è®­ç»ƒLSTMæ¨¡å‹è¿›è¡ŒRULé¢„æµ‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # å¤šå˜é‡æ¨¡å¼ï¼ˆæ¨èï¼Œè‡ªåŠ¨è·å–æ‰€æœ‰æµ‹ç‚¹ï¼‰
  python -m backend.algorithm.train --mode multivariate --asset_id COMP-ATLAS-01
  
  # å•æµ‹ç‚¹æ¨¡å¼
  python -m backend.algorithm.train --mode single --asset_id COMP-ATLAS-01 --metric_id COMP01_OIL_TEMP
  
  # è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
  python -m backend.algorithm.train --mode multivariate --asset_id COMP-ATLAS-01 --epochs 50 --lstm_units 128 64 32
        """
    )
    
    # è®­ç»ƒæ¨¡å¼é€‰æ‹©
    parser.add_argument(
        "--mode", 
        type=str, 
        choices=["single", "multivariate"], 
        default="multivariate",
        help="è®­ç»ƒæ¨¡å¼ï¼šsingle=å•æµ‹ç‚¹ï¼Œmultivariate=å¤šå˜é‡ï¼ˆä¸€ä¸ªè®¾å¤‡ä¸€ä¸ªæ¨¡å‹ï¼Œè‡ªåŠ¨è·å–æ‰€æœ‰æµ‹ç‚¹ï¼‰"
    )
    
    # è®­ç»ƒå‚æ•°é…ç½®
    parser.add_argument("--asset_id", type=str, default="COMP-ATLAS-01", help="è®¾å¤‡ID")
    parser.add_argument("--metric_id", type=str, default="COMP01_OIL_TEMP", help="æµ‹ç‚¹IDï¼ˆä»…å•æµ‹ç‚¹æ¨¡å¼éœ€è¦ï¼‰")
    parser.add_argument("--sequence_length", type=int, default=30, help="åºåˆ—é•¿åº¦ï¼ˆæ—¶é—´çª—å£å¤§å°ï¼‰")
    parser.add_argument("--lstm_units", type=int, nargs="+", default=[128, 64], help="LSTMå±‚å•å…ƒæ•°ï¼Œä¾‹å¦‚ï¼š--lstm_units 128 64")
    parser.add_argument("--epochs", type=int, default=32, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=64, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--model_path", type=str, default=None, help="æ¨¡å‹ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰")
    parser.add_argument("--no_plots", action="store_true", help="ä¸ä¿å­˜è®­ç»ƒæ›²çº¿å›¾")
    
    args = parser.parse_args()
    
    if args.mode == "multivariate":
        # å¤šå˜é‡æ¨¡å¼ï¼šè‡ªåŠ¨ä»æ•°æ®åº“è·å–è®¾å¤‡çš„æ‰€æœ‰PROCESSç±»å‹æµ‹ç‚¹
        train_multivariate(
            asset_id=args.asset_id,
            sequence_length=args.sequence_length,
            lstm_units=args.lstm_units,
            epochs=args.epochs,
            batch_size=args.batch_size,
            model_save_path=args.model_path,
            save_plots=not args.no_plots,
        )
    else:
        # å•æµ‹ç‚¹æ¨¡å¼
        train_single_metric(
            asset_id=args.asset_id,
            metric_id=args.metric_id,
            sequence_length=args.sequence_length,
            lstm_units=args.lstm_units,
            epochs=args.epochs,
            batch_size=args.batch_size,
            model_save_path=args.model_path,
            save_plots=not args.no_plots,
        )


if __name__ == "__main__":
    main()

